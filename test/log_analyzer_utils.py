import streamlit as st
import pandas as pd
import json


class LogAnalyzerUtils:
    """æ—¥å¿—åˆ†æå·¥å…·è¾…åŠ©ç±»"""

    @staticmethod
    def apply_text_filters(line, text_filters, logic_operator="AND"):
        """åº”ç”¨æ–‡æœ¬è¿‡æ»¤å™¨ - æ”¯æŒå¤šæ¡ä»¶ç»„åˆæŸ¥è¯¢"""
        if not text_filters:
            return True

        include_line = True if logic_operator == "AND" else False

        for filter_config in text_filters:
            filter_type = filter_config.get('type')
            filter_value = filter_config.get('value')
            filter_operator = filter_config.get('operator', 'åŒ…å«')  # é»˜è®¤æ“ä½œç¬¦
            filter_match = False

            # å¤„ç†CSVåˆ—ç­›é€‰æ¡ä»¶
            if filter_type == 'keyword' and filter_config.get('column'):
                column_name = filter_config.get('column')

                # ä»è¡Œä¸­æå–è¯¥åˆ—çš„å€¼ - æ”¯æŒå¤šç§åˆ†éš”ç¬¦
                try:
                    # å°è¯•å¤šç§å¯èƒ½çš„åˆ†éš”ç¬¦
                    separators = ['\t', '|', ',']
                    columns = None

                    for sep in separators:
                        if sep in line:
                            columns = line.split(sep)
                            break

                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ†éš”ç¬¦ï¼Œä½¿ç”¨ç©ºæ ¼åˆ†å‰²
                    if columns is None:
                        columns = line.split()

                    if st.session_state.csv_columns and len(columns) == len(st.session_state.csv_columns):
                        column_index = st.session_state.csv_columns.index(column_name)
                        column_value = columns[column_index].strip()

                        # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå€¼ï¼ˆåŒ…æ‹¬Noneã€nullã€ç©ºå­—ç¬¦ä¸²ç­‰ï¼‰
                        def is_empty_value(value):
                            if value is None:
                                return True
                            value_str = str(value).strip().lower()
                            return value_str in ['', 'none', 'null', 'nan', 'undefined', 'null']

                        if filter_operator == 'æœ‰å€¼':
                            filter_match = not is_empty_value(column_value)  # æœ‰å…·ä½“å†…å®¹
                        elif filter_operator == 'æ²¡æœ‰å€¼':
                            filter_match = is_empty_value(column_value)  # å€¼ä¸ºç©º
                        elif filter_operator == 'åŒ…å«':
                            filter_match = filter_value.lower() in column_value.lower()
                        elif filter_operator == 'ç­‰äº':
                            filter_match = column_value == filter_value
                        elif filter_operator == 'å¼€å¤´ä¸º':
                            filter_match = column_value.startswith(filter_value)
                        elif filter_operator == 'ç»“å°¾ä¸º':
                            filter_match = column_value.endswith(filter_value)

                        # è°ƒè¯•ä¿¡æ¯
                        print(
                            f"DEBUG - åˆ—: {column_name}, å€¼: '{column_value}', æ“ä½œç¬¦: {filter_operator}, åŒ¹é…: {filter_match}")

                except Exception as e:
                    print(f"DEBUG - è§£æé”™è¯¯: {e}")
                    filter_match = False

            # æ—¥å¿—çº§åˆ«è¿‡æ»¤
            # æ—¥å¿—çº§åˆ«è¿‡æ»¤ - ä¿®å¤DEBUGåˆ¤æ–­
            elif filter_type == "log_level":
                level_match = False
                if "é”™è¯¯" in filter_value and any(word in line.upper() for word in [' ERROR', ' ERR ', ']ERROR', ']ERR']):
                    level_match = True
                if "è­¦å‘Š" in filter_value and any(
                        word in line.upper() for word in [' WARN', ' WARNING', ']WARN', ']WARNING']):
                    level_match = True
                if "ä¿¡æ¯" in filter_value and any(
                        word in line.upper() for word in [' INFO', ' INFORMATION', ']INFO', ']INFORMATION']):
                    level_match = True
                if "è°ƒè¯•" in filter_value and any(word in line.upper() for word in [' DEBUG', ' DBG', ']DEBUG', ']DBG']):
                    level_match = True
                filter_match = level_match

            # IPåœ°å€è¿‡æ»¤
            elif filter_type == "ip_filter":
                filter_match = filter_value in line

            # çŠ¶æ€ç è¿‡æ»¤
            elif filter_type == "status_code":
                codes = [code.strip() for code in filter_value.split(',')]
                filter_match = any(
                    f" {code} " in line or line.endswith(f" {code}") or f" {code}" in line for code in codes)

            # æ™®é€šå…³é”®è¯è¿‡æ»¤
            elif filter_type == "keyword":
                filter_match = filter_value.lower() in line.lower()

            # ä»…æ˜¾ç¤ºé”™è¯¯
            elif filter_type == "show_only_errors":
                filter_match = any(word in line.upper() for word in ['ERROR', 'ERR', 'FAIL', 'EXCEPTION'])

            # éšè—è°ƒè¯•
            elif filter_type == "hide_debug":
                filter_match = not any(word in line.upper() for word in ['DEBUG', 'DBG'])

            # æ ¹æ®é€»è¾‘è¿ç®—ç¬¦ç»„åˆç»“æœ
            if logic_operator == "AND":
                include_line = include_line and filter_match
                if not include_line:  # AND é€»è¾‘ä¸‹æœ‰ä¸€ä¸ªä¸åŒ¹é…å°±å¯ä»¥æå‰é€€å‡º
                    break
            else:  # OR é€»è¾‘
                include_line = include_line or filter_match
                if include_line:  # OR é€»è¾‘ä¸‹æœ‰ä¸€ä¸ªåŒ¹é…å°±å¯ä»¥æå‰é€€å‡º
                    break

        return include_line

    @staticmethod
    def apply_json_filters(df, json_filters, logic_operator="AND"):
        """åº”ç”¨JSONå­—æ®µè¿‡æ»¤å™¨ - æ”¯æŒå¤šæ¡ä»¶ç»„åˆæŸ¥è¯¢"""
        if not json_filters or df.empty:
            return df

        mask = pd.Series([True] * len(df))

        for filter_config in json_filters:
            column = filter_config.get('column')
            field = filter_config.get('field')
            value = filter_config.get('value')
            value_range = filter_config.get('value_range')

            if not column or not field:
                continue

            def check_json_condition(row):
                try:
                    if pd.isna(row[column]):
                        return False
                    if isinstance(row[column], str):
                        json_data = json.loads(row[column])
                        if field in json_data:
                            field_value = json_data[field]

                            # èŒƒå›´ç­›é€‰
                            if value_range:
                                if isinstance(field_value, (int, float)):
                                    return value_range[0] <= field_value <= value_range[1]
                                return False

                            # å€¼ç­›é€‰
                            if value:
                                return str(value).lower() in str(field_value).lower()

                            return True  # å¦‚æœæ²¡æœ‰å€¼å’ŒèŒƒå›´ï¼Œåªè¦æœ‰è¿™ä¸ªå­—æ®µå°±è¿”å›True
                except:
                    pass
                return False

            column_mask = df.apply(check_json_condition, axis=1)

            if logic_operator == "AND":
                mask = mask & column_mask
            else:  # OR é€»è¾‘
                mask = mask | column_mask

        return df[mask]

    @staticmethod
    def detect_log_level(line):
        """æ£€æµ‹æ—¥å¿—çº§åˆ« - ä¿®å¤DEBUGåˆ¤æ–­"""
        line_upper = line.upper()
        # æ·»åŠ ç©ºæ ¼æˆ–æ–¹æ‹¬å·å‰ç¼€ï¼Œé¿å…åŒ¹é…åˆ°å•è¯ä¸­çš„éƒ¨åˆ†
        if any(word in line_upper for word in [' ERROR', ' ERR ', ']ERROR', ']ERR']):
            return "ğŸ”´ é”™è¯¯"
        elif any(word in line_upper for word in [' WARN', ' WARNING', ']WARN', ']WARNING']):
            return "ğŸŸ¡ è­¦å‘Š"
        elif any(word in line_upper for word in [' INFO', ' INFORMATION', ']INFO', ']INFORMATION']):
            return "ğŸ”µ ä¿¡æ¯"
        elif any(word in line_upper for word in [' DEBUG', ' DBG', ']DEBUG', ']DBG']):
            return "ğŸŸ¢ è°ƒè¯•"
        else:
            return "âšª å…¶ä»–"

    @staticmethod
    def extract_timestamp(line):
        """æå–æ—¶é—´æˆ³ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        import re
        # å¸¸è§çš„æ—¶é—´æˆ³æ ¼å¼
        timestamp_patterns = [
            r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}',
            r'\d{2}/\d{2}/\d{4} \d{2}:\d{2}:\d{2}',
            r'\d{2}:\d{2}:\d{2}',
        ]

        for pattern in timestamp_patterns:
            match = re.search(pattern, line)
            if match:
                return match.group()
        return "æœªçŸ¥æ—¶é—´"

    @staticmethod
    def find_keyword_position(line, keyword):
        """æŸ¥æ‰¾å…³é”®è¯ä½ç½®"""
        if not keyword:
            return "æœªæŒ‡å®š"
        position = line.lower().find(keyword.lower())
        if position != -1:
            return f"ç¬¬ {position + 1} å­—ç¬¦"
        return "æœªæ‰¾åˆ°"
