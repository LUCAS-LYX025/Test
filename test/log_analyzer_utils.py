import pandas as pd
import json


class LogAnalyzerUtils:
    """æ—¥å¿—åˆ†æå·¥å…·è¾…åŠ©ç±»"""

    @staticmethod
    def apply_text_filters(line, text_filters, logic_operator="AND"):
        """åº”ç”¨æ–‡æœ¬è¿‡æ»¤å™¨ - æ”¯æŒå¤šæ¡ä»¶ç»„åˆæŸ¥è¯¢"""
        if not text_filters:
            return True

        include_line = True if logic_operator == "AND" else False

        for filter_config in text_filters:
            filter_type = filter_config.get('type')
            filter_value = filter_config.get('value')
            filter_match = False

            if not filter_value:  # ç©ºæ¡ä»¶è·³è¿‡
                continue

            if filter_type == "log_level":
                # æ—¥å¿—çº§åˆ«è¿‡æ»¤
                level_match = False
                if "é”™è¯¯" in filter_value and any(word in line.upper() for word in ['ERROR', 'ERR']):
                    level_match = True
                if "è­¦å‘Š" in filter_value and any(word in line.upper() for word in ['WARN', 'WARNING']):
                    level_match = True
                if "ä¿¡æ¯" in filter_value and any(word in line.upper() for word in ['INFO', 'INFORMATION']):
                    level_match = True
                if "è°ƒè¯•" in filter_value and any(word in line.upper() for word in ['DEBUG', 'DBG']):
                    level_match = True
                filter_match = level_match

            elif filter_type == "ip_filter":
                # IPåœ°å€è¿‡æ»¤
                filter_match = filter_value in line

            elif filter_type == "status_code":
                # çŠ¶æ€ç è¿‡æ»¤
                codes = [code.strip() for code in filter_value.split(',')]
                filter_match = any(
                    f" {code} " in line or line.endswith(f" {code}") or f" {code}" in line for code in codes)

            elif filter_type == "keyword":
                # å…³é”®è¯è¿‡æ»¤
                filter_match = filter_value.lower() in line.lower()

            elif filter_type == "show_only_errors":
                # ä»…æ˜¾ç¤ºé”™è¯¯
                filter_match = any(word in line.upper() for word in ['ERROR', 'ERR', 'FAIL', 'EXCEPTION'])

            elif filter_type == "hide_debug":
                # éšè—è°ƒè¯•
                filter_match = not any(word in line.upper() for word in ['DEBUG', 'DBG'])

            # æ ¹æ®é€»è¾‘è¿ç®—ç¬¦ç»„åˆç»“æœ
            if logic_operator == "AND":
                include_line = include_line and filter_match
                if not include_line:  # AND é€»è¾‘ä¸‹æœ‰ä¸€ä¸ªä¸åŒ¹é…å°±å¯ä»¥æå‰é€€å‡º
                    break
            else:  # OR é€»è¾‘
                include_line = include_line or filter_match
                if include_line:  # OR é€»è¾‘ä¸‹æœ‰ä¸€ä¸ªåŒ¹é…å°±å¯ä»¥æå‰é€€å‡º
                    break

        return include_line

    @staticmethod
    def apply_json_filters(df, json_filters, logic_operator="AND"):
        """åº”ç”¨JSONå­—æ®µè¿‡æ»¤å™¨ - æ”¯æŒå¤šæ¡ä»¶ç»„åˆæŸ¥è¯¢"""
        if not json_filters or df.empty:
            return df

        mask = pd.Series([True] * len(df))

        for filter_config in json_filters:
            column = filter_config.get('column')
            field = filter_config.get('field')
            value = filter_config.get('value')
            value_range = filter_config.get('value_range')

            if not column or not field:
                continue

            def check_json_condition(row):
                try:
                    if pd.isna(row[column]):
                        return False
                    if isinstance(row[column], str):
                        json_data = json.loads(row[column])
                        if field in json_data:
                            field_value = json_data[field]

                            # èŒƒå›´ç­›é€‰
                            if value_range:
                                if isinstance(field_value, (int, float)):
                                    return value_range[0] <= field_value <= value_range[1]
                                return False

                            # å€¼ç­›é€‰
                            if value:
                                return str(value).lower() in str(field_value).lower()

                            return True  # å¦‚æœæ²¡æœ‰å€¼å’ŒèŒƒå›´ï¼Œåªè¦æœ‰è¿™ä¸ªå­—æ®µå°±è¿”å›True
                except:
                    pass
                return False

            column_mask = df.apply(check_json_condition, axis=1)

            if logic_operator == "AND":
                mask = mask & column_mask
            else:  # OR é€»è¾‘
                mask = mask | column_mask

        return df[mask]

    @staticmethod
    def detect_log_level(line):
        """æ£€æµ‹æ—¥å¿—çº§åˆ«"""
        line_upper = line.upper()
        if any(word in line_upper for word in ['ERROR', 'ERR']):
            return "ğŸ”´ é”™è¯¯"
        elif any(word in line_upper for word in ['WARN', 'WARNING']):
            return "ğŸŸ¡ è­¦å‘Š"
        elif any(word in line_upper for word in ['INFO', 'INFORMATION']):
            return "ğŸ”µ ä¿¡æ¯"
        elif any(word in line_upper for word in ['DEBUG', 'DBG']):
            return "ğŸŸ¢ è°ƒè¯•"
        else:
            return "âšª å…¶ä»–"

    @staticmethod
    def extract_timestamp(line):
        """æå–æ—¶é—´æˆ³ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        import re
        # å¸¸è§çš„æ—¶é—´æˆ³æ ¼å¼
        timestamp_patterns = [
            r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}',
            r'\d{2}/\d{2}/\d{4} \d{2}:\d{2}:\d{2}',
            r'\d{2}:\d{2}:\d{2}',
        ]

        for pattern in timestamp_patterns:
            match = re.search(pattern, line)
            if match:
                return match.group()
        return "æœªçŸ¥æ—¶é—´"

    @staticmethod
    def find_keyword_position(line, keyword):
        """æŸ¥æ‰¾å…³é”®è¯ä½ç½®"""
        if not keyword:
            return "æœªæŒ‡å®š"
        position = line.lower().find(keyword.lower())
        if position != -1:
            return f"ç¬¬ {position + 1} å­—ç¬¦"
        return "æœªæ‰¾åˆ°"